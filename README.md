# 🦜🔗 LangChain Learning Repository

This repository contains my complete learning journey with **LangChain** and its ecosystem — from scratch to advanced.
It includes practice scripts, experiments, and small projects covering core modules and integrations.

## 📚 Topics Covered

* **LangChain Core**
* **LangChain Expression Language (LCEL)**
* **Retrieval-Augmented Generation (RAG)**
* **Splitting**
* **Chunking**
* **Embedding**
* **Vectore Stores**
* **LangSmith** – Observability and debugging
* **LangServe** – Deploying LangChain apps as APIs
* **LangGraph** – Multi-agent and graph-based workflows



## 🚀 Tech Stack

* **Python 3.10+**
* **LangChain**
* **Groq / OpenAI / Other LLM Providers**
* **Vector Databases** (FAISS, Pinecone, ChromaDB, etc.)



## 🛠 Setup Instructions

1. **Clone the repo**

   ```bash
   git clone https://github.com/choudaryhussainali/Langchain_Learnings.git
   cd langchain-learning
   ```

2. **Create a virtual environment**

   ```bash
   python -m venv venv
   source venv/bin/activate  # macOS/Linux
   venv\Scripts\activate     # Windows
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Set environment variables**
   Create a `.env` file in the root directory:

   ```
   GROQ_API_KEY=your_api_key_here
   OPENAI_API_KEY=your_api_key_here
   ```

5. **Run an example**

   ```bash
   python scripts/example.py
   ```

## 📌 Notes

* This repo is purely for **learning and experimentation**.
* Some examples require API keys for LLM providers like **Groq** or **OpenAI**.
* The code is modular so you can reuse components in other projects.


## 📄 License

This project is proprietary and confidential. All rights reserved.

```
© 2025 HUSSAIN ALI. This code may not be copied, modified, distributed, or used without explicit permission.
```

---

## 📬 Contact

For questions or collaboration requests:

* 📧 Email: [choudaryhussainali@outlook.com](mailto:choudaryhussainali@outlook.com)
* 🌐 GitHub: [choudaryhussainali](https://github.com/choudaryhussainali)

---



