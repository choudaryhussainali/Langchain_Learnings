{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e00a3a",
   "metadata": {},
   "source": [
    "# PromptTemplate in Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83c1f7",
   "metadata": {},
   "source": [
    "Passing a template as an input to LLms..\n",
    "Template may contain variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llmModel = ChatGroq(\n",
    "    model = \"llama3-70b-8192\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060d35ae",
   "metadata": {},
   "source": [
    "# Prompts and PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"tell me a {Adjective} story about {topic}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    Adjective = \"curious\",\n",
    "    topic = \"imran khan\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmModel.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1164d7b2",
   "metadata": {},
   "source": [
    "# using Chat Model prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llmModel = ChatGroq(\n",
    "    model = \"llama3-70b-8192\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac895e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "\n",
    "    [\n",
    "        ('system', \"You are a {profession} Expert on {topic}\"),\n",
    "        ('user', 'Hello Mr {profession}, can you please answer me a question?'),\n",
    "        ('ai', 'Sure'),\n",
    "        ('user', '{user_input}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = chat_template.format(\n",
    "    profession = \"mechanical\",\n",
    "    topic = 'Cars',\n",
    "    user_input = 'Tesla'\n",
    ")\n",
    "\n",
    "response = llmModel.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea6780",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27925c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"¡hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"¡adiós!\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "chain = final_prompt | llmModel\n",
    "\n",
    "res = chain.invoke({\"input\": \"How are you?\"})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b5b1f",
   "metadata": {},
   "source": [
    "# Output PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd04bf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Russia'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answer` key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "json_chain = json_prompt | llmModel | json_parser\n",
    "\n",
    "res  = json_chain.invoke({\"question\": \"What is the biggest country?\"})\n",
    "\n",
    "print(res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
